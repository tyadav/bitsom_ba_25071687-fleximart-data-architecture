# FlexiMart Data Architecture Project

 **Student Name:** Tej Yadav  
 **Student ID:** BITSOM_BA_25071687  
 **Email:** tej.yadav@yahoo.com  
 **Date:** Jan 2nd, 2026  

**ğŸ“Œ Overview**
This project implements a complete data architecture for FlexiMart, covering ETL pipelines, NoSQL analysis, and a star-schema data warehouse. It demonstrates how raw operational data can be transformed into business-ready insights, with clear documentation, reproducible scripts, and OLAP queries for analytics.

**FlexiMart Data Engineering Pipeline**  
FlexiMart is an e-commerce company aiming to build a robust analytics system from raw CSV files.  
This project demonstrates the **end-to-end data pipeline**: from messy source data to a clean relational database, NoSQL analysis, and a star-schema data warehouse.

---
**ğŸ“‚ Repository Structure**  
<pre>
bitsom_ba_25071687-fleximart-data-architecture/
â”‚
â”œâ”€â”€ README.md                         # Root documentation 
â”œâ”€â”€ .gitignore                        # Ignore unnecessary files 
â”œâ”€â”€ pytest.ini                        # Global test configuration
â”‚
â”œâ”€â”€ data/                             # Input data files (provided)
â”‚   â”œâ”€â”€ customers_raw.csv
â”‚   â”œâ”€â”€ products_raw.csv
â”‚   â””â”€â”€ sales_raw.csv
â”‚
â”œâ”€â”€ part1-database-etl/
â”‚   â”œâ”€â”€ README.md                      # Part 1 overview
â”‚   â”œâ”€â”€ etl_pipeline.py
â”‚   â”œâ”€â”€ schema_documentation.md
â”‚   â”œâ”€â”€ business_queries.sql
â”‚   â”œâ”€â”€ data_quality_report.txt        # Generated by ETL script
â”‚   â””â”€â”€ requirements.txt               # Python dependencies
â”‚
â”œâ”€â”€ part2-nosql/
â”‚   â”œâ”€â”€ README.md                      # Part 2 overview
â”‚   â”œâ”€â”€ nosql_analysis.md
â”‚   â”œâ”€â”€ mongodb_operations.py
â”‚   â””â”€â”€ products_catalog.json
â”‚
â””â”€â”€ part3-datawarehouse/
â”‚   â”œâ”€â”€ README.md                        # Part 3 overview 
â”‚   â”œâ”€â”€ star_schema_design.md 
â”‚   â”œâ”€â”€ warehouse_schema.sql 
â”‚   â”œâ”€â”€ warehouse_data.sql 
â”‚   â””â”€â”€ analytics_queries.sql
â”œâ”€â”€ tests/                          # All test files here
â”‚   â”œâ”€â”€ test_etl.py                 # ETL pipeline tests
â”‚   â”œâ”€â”€ test_nosql.py               # NoSQL sanity checks
â”‚   â””â”€â”€ test_warehouse.py           # Warehouse schema checks
â”‚
â””â”€â”€ output/                         # Sample outputs and reports 
    â”œâ”€â”€ monthly_sales_output.csv 
    â”œâ”€â”€ top_products_output.csv 
    â”œâ”€â”€ customer_segments_output.csv 
    â””â”€â”€ etl_log.txt
</pre>
---

1. **ETL Pipeline (MySQL)**  
   - Ingest raw CSV files (`customers_raw.csv`, `products_raw.csv`, `sales_raw.csv`)  
   - Clean and standardize data (deduplication, missing values, phone/date normalization)  
   - Load into relational tables

2. **Database Documentation**  
   - Schema diagrams  
   - Relationships between customers, products, and sales

3. **Business Queries (SQL)**  
   - Customer segmentation  
   - City-wise revenue  
   - Top-selling products  
   - Repeat customers analysis

4. **NoSQL Analysis (MongoDB)**  
   - Product catalog design  
   - Sample queries for flexible product attributes

5. **Data Warehouse (Star Schema)**  
   - Fact table: `fact_sales`  
   - Dimension tables: `dim_customers`, `dim_products`, `dim_date`  
   - Analytical reports (e.g., monthly revenue trends, product category performance)

6. **ğŸ› ï¸ Tech Stack**  
   - **Languages:** Python (ETL scripts), SQL  
   - **Databases:** PostgreSQL / MySQL, MongoDB  
   - **Data Warehouse:** Star Schema design  
   - **Tools:** psycopg2 / SQLAlchemy, Pandas, ERD tools

7. **ğŸš€ Setup Instructions**  
      **MySQL**    
        mysql -u root -p -e "CREATE DATABASE fleximart;"         
        mysql -u root -p -e "CREATE DATABASE fleximart_dw;"          
        mysql -u root -p fleximart < part1-database-etl/business_queries.sql        
        mysql -u root -p fleximart_dw < part3-datawarehouse/warehouse_schema.sql        
        mysql -u root -p fleximart_dw < part3-datawarehouse/warehouse_data.sql       
        mysql -u root -p fleximart_dw < part3-datawarehouse/analytics_queries.sql       

      **MongoDB**       
        mongoimport --db fleximart --collection products --file part2-nosql/products_catalog.json      
        mongo < part2-nosql/mongodb_operations.py      

      **Python**       
        pip install -r part1-database-etl/requirements.txt      
        python part1-database-etl/etl_pipeline.py     
        pytest tests/ -v       

8. **Challenges Faced**   
   - Foreign Key Constraint Errors  
     Challenge: Fact table inserts failed due to missing dimension keys.
     Solution: Modified schema to use manual surrogate keys and reloaded dimensions before facts.

   - Duplicate Data Loads  
     Challenge: Re-running inserts created duplicate rows in dimension tables.
     Solution: Used TRUNCATE with foreign key checks disabled to reset tables before reloads.

9. **Key Learnings**   
   Through this project, I learned how to:
   -  Design modular ETL pipelines for relational databases.
   -  Enforce schema integrity and troubleshoot foreign key constraints.
   -  Build a star-schema warehouse for OLAP analysis.
   -  Integrate relational and NoSQL systems for flexible analytics.
   -  Validate data quality and write analytical SQL queries to support business decision-making.

10. **Deliverables**    
    -  Part 1: ETL pipeline, schema documentation, business queries, data quality report.
    -  Part 2: NoSQL analysis, MongoDB operations, product catalog JSON.
    -  Part 3: Star schema design, warehouse schema/data, OLAP queries with sample outputs.

   Documentation: Root README.md and supporting README.md markdown files in each part.
